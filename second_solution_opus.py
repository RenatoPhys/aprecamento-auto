"""
Modelo de Elasticidade de Demanda - Financiamento de Ve√≠culos
An√°lise completa de elasticidade-pre√ßo e simula√ß√£o de cen√°rios
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from datetime import datetime

# Bibliotecas para modelagem
import statsmodels.formula.api as smf
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error
from sklearn.preprocessing import StandardScaler
from scipy import stats

warnings.filterwarnings('ignore')

# Configura√ß√£o de visualiza√ß√£o
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# ==========================================
# 1. CARREGAMENTO E PREPARA√á√ÉO DOS DADOS
# ==========================================

def load_and_prepare_data(anomes_list):
    """
    Carrega e prepara os dados para modelagem
    
    Parameters:
    anomes_list: lista com os per√≠odos a serem analisados
    """
    
    # Query parametrizada
    anomes_str = ','.join([str(x) for x in anomes_list])
    query = f'''
        SELECT *
        FROM tb_funil_veiculos
        WHERE anomes IN ({anomes_str})
    '''
    
    # Carregamento dos dados
    print(f"üìä Carregando dados dos per√≠odos: {anomes_str}")
    df = wr.athena.read_sql(query)
    
    # Convers√£o de tipos
    df['pct_txa_ofrt_simu_pmro_vers'] = df['pct_txa_ofrt_simu_pmro_vers'].astype(float)
    df['valor_prod'] = df['valor_prod'].astype(float)
    
    # Cria√ß√£o de features adicionais
    df['log_valor_prod'] = np.log1p(df['valor_prod'])  # Log para normaliza√ß√£o
    df['taxa_squared'] = df['pct_txa_ofrt_simu_pmro_vers'] ** 2  # Termo quadr√°tico
    
    print(f"‚úÖ Dados carregados: {df.shape[0]:,} registros")
    print(f"üìÖ Per√≠odos dispon√≠veis: {df['anomes'].unique()}")
    
    return df

# ==========================================
# 2. AN√ÅLISE EXPLORAT√ìRIA (EDA)
# ==========================================

def perform_eda(df, prod_var, taxa_var, cat_vars):
    """
    Realiza an√°lise explorat√≥ria dos dados
    """
    print("\n" + "="*60)
    print("üìà AN√ÅLISE EXPLORAT√ìRIA DOS DADOS")
    print("="*60)
    
    # Estat√≠sticas descritivas
    print("\nüìä Estat√≠sticas da Taxa de Juros:")
    print(df[taxa_var].describe())
    
    print("\nüìä Estat√≠sticas da Produ√ß√£o:")
    print(df[prod_var].describe())
    
    # Criar figura com subplots
    fig = plt.figure(figsize=(20, 12))
    
    # 1. Distribui√ß√£o da Taxa
    ax1 = plt.subplot(2, 3, 1)
    df[taxa_var].hist(bins=50, edgecolor='black', alpha=0.7)
    plt.axvline(df[taxa_var].mean(), color='red', linestyle='--', label=f'M√©dia: {df[taxa_var].mean():.2f}%')
    plt.xlabel('Taxa (%)')
    plt.ylabel('Frequ√™ncia')
    plt.title('Distribui√ß√£o da Taxa de Juros')
    plt.legend()
    
    # 2. Distribui√ß√£o da Produ√ß√£o
    ax2 = plt.subplot(2, 3, 2)
    df[prod_var].hist(bins=50, edgecolor='black', alpha=0.7)
    plt.axvline(df[prod_var].mean(), color='red', linestyle='--', label=f'M√©dia: R$ {df[prod_var].mean():,.0f}')
    plt.xlabel('Valor Produzido (R$)')
    plt.ylabel('Frequ√™ncia')
    plt.title('Distribui√ß√£o da Produ√ß√£o')
    plt.legend()
    
    # 3. Scatter plot Taxa vs Produ√ß√£o
    ax3 = plt.subplot(2, 3, 3)
    plt.scatter(df[taxa_var], df[prod_var], alpha=0.5, s=10)
    z = np.polyfit(df[taxa_var], df[prod_var], 1)
    p = np.poly1d(z)
    plt.plot(df[taxa_var].sort_values(), p(df[taxa_var].sort_values()), 
             "r--", alpha=0.8, label='Tend√™ncia Linear')
    plt.xlabel('Taxa (%)')
    plt.ylabel('Valor Produzido (R$)')
    plt.title('Rela√ß√£o Taxa vs Produ√ß√£o')
    plt.legend()
    
    # 4. Boxplot da Taxa por UF
    ax4 = plt.subplot(2, 3, 4)
    if 'uf' in cat_vars:
        df.boxplot(column=taxa_var, by='uf', ax=ax4, rot=90)
        plt.suptitle('')
        plt.title('Distribui√ß√£o da Taxa por UF')
        plt.xlabel('UF')
        plt.ylabel('Taxa (%)')
    
    # 5. Produ√ß√£o m√©dia por segmento
    ax5 = plt.subplot(2, 3, 5)
    if 'seg_cliente' in cat_vars:
        prod_by_seg = df.groupby('seg_cliente')[prod_var].mean().sort_values(ascending=False)
        prod_by_seg.plot(kind='bar', ax=ax5)
        plt.title('Produ√ß√£o M√©dia por Segmento de Cliente')
        plt.xlabel('Segmento')
        plt.ylabel('Produ√ß√£o M√©dia (R$)')
        plt.xticks(rotation=45)
    
    # 6. Heatmap de correla√ß√£o
    ax6 = plt.subplot(2, 3, 6)
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    correlation_matrix = df[numeric_cols].corr()
    sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', 
                center=0, ax=ax6, cbar_kws={'label': 'Correla√ß√£o'})
    plt.title('Matriz de Correla√ß√£o')
    
    plt.tight_layout()
    plt.show()
    
    # An√°lise por per√≠odo
    print("\nüìÖ An√°lise por Per√≠odo (anomes):")
    period_analysis = df.groupby('anomes').agg({
        prod_var: ['count', 'mean', 'sum'],
        taxa_var: ['mean', 'std']
    }).round(2)
    print(period_analysis)

# ==========================================
# 3. AN√ÅLISE DE FEATURES E IMPORT√ÇNCIA
# ==========================================

def analyze_feature_importance(df, prod_var, taxa_var, cat_vars):
    """
    Analisa a import√¢ncia das features para o modelo
    """
    print("\n" + "="*60)
    print("üîç AN√ÅLISE DE IMPORT√ÇNCIA DAS FEATURES")
    print("="*60)
    
    # Criar dataframe agregado
    df['range_taxa'] = pd.qcut(df[taxa_var], q=5, labels=['Muito Baixa', 'Baixa', 'M√©dia', 'Alta', 'Muito Alta'])
    
    results = []
    
    # An√°lise univariada para cada vari√°vel categ√≥rica
    for var in cat_vars:
        # Calcular produ√ß√£o m√©dia por categoria
        prod_by_cat = df.groupby(var)[prod_var].agg(['mean', 'std', 'count'])
        
        # ANOVA para testar signific√¢ncia
        groups = [group[prod_var].values for name, group in df.groupby(var)]
        f_stat, p_value = stats.f_oneway(*groups)
        
        # Coeficiente de varia√ß√£o
        cv = prod_by_cat['std'].mean() / prod_by_cat['mean'].mean()
        
        results.append({
            'Vari√°vel': var,
            'Categorias': df[var].nunique(),
            'F-statistic': f_stat,
            'P-value': p_value,
            'Coef. Varia√ß√£o': cv,
            'Significante': 'Sim' if p_value < 0.05 else 'N√£o'
        })
    
    # DataFrame com resultados
    importance_df = pd.DataFrame(results)
    importance_df = importance_df.sort_values('F-statistic', ascending=False)
    
    print("\nüìä Import√¢ncia das Vari√°veis Categ√≥ricas (ANOVA):")
    print(importance_df.to_string(index=False))
    
    # Visualiza√ß√£o
    fig, axes = plt.subplots(1, 2, figsize=(15, 5))
    
    # F-statistics
    axes[0].barh(importance_df['Vari√°vel'], importance_df['F-statistic'])
    axes[0].set_xlabel('F-statistic')
    axes[0].set_title('Import√¢ncia das Features (F-statistic)')
    axes[0].invert_yaxis()
    
    # P-values
    axes[1].barh(importance_df['Vari√°vel'], -np.log10(importance_df['P-value']))
    axes[1].axvline(x=-np.log10(0.05), color='r', linestyle='--', label='p=0.05')
    axes[1].set_xlabel('-log10(P-value)')
    axes[1].set_title('Signific√¢ncia Estat√≠stica das Features')
    axes[1].legend()
    axes[1].invert_yaxis()
    
    plt.tight_layout()
    plt.show()
    
    return importance_df

# ==========================================
# 4. PREPARA√á√ÉO PARA MODELAGEM
# ==========================================

def prepare_modeling_data(df, prod_var, taxa_var, cat_vars, train_periods, test_periods):
    """
    Prepara os dados para treino e teste
    """
    print("\n" + "="*60)
    print("üîß PREPARA√á√ÉO DOS DADOS PARA MODELAGEM")
    print("="*60)
    
    # Criar range de taxa
    df['range_taxa'] = pd.qcut(df[taxa_var], q=5)
    
    # Agrega√ß√£o dos dados
    agg_dict = {
        'qtd_obs': (prod_var, 'count'),
        'taxa_media': (taxa_var, 'mean'),
        'producao_simulacao': (prod_var, 'mean'),
        'producao_total': (prod_var, 'sum')
    }
    
    aux = df.groupby(cat_vars + ['range_taxa', 'anomes'], observed=True).agg(**agg_dict).reset_index()
    
    # Renomear coluna de taxa
    aux.rename(columns={'taxa_media': taxa_var}, inplace=True)
    
    # Separar treino e teste por per√≠odo
    train_data = aux[aux['anomes'].isin(train_periods)].copy()
    test_data = aux[aux['anomes'].isin(test_periods)].copy()
    
    print(f"üìä Dados de Treino: {len(train_data)} registros (per√≠odos: {train_periods})")
    print(f"üìä Dados de Teste: {len(test_data)} registros (per√≠odos: {test_periods})")
    
    # Converter vari√°veis categ√≥ricas
    for var in cat_vars:
        train_data[var] = train_data[var].astype('category')
        test_data[var] = test_data[var].astype('category')
    
    return train_data, test_data

# ==========================================
# 5. MODELAGEM E ELASTICIDADES
# ==========================================

def build_elasticity_model(train_data, test_data, prod_var, taxa_var, cat_vars):
    """
    Constr√≥i modelo de elasticidade com intera√ß√µes
    """
    print("\n" + "="*60)
    print("üìä CONSTRU√á√ÉO DO MODELO DE ELASTICIDADE")
    print("="*60)
    
    # Vari√°vel dependente
    y = 'producao_simulacao'
    
    # Construir f√≥rmula do modelo com intera√ß√µes
    formula = f'{y} ~ {taxa_var}'
    
    # Adicionar intera√ß√µes para capturar elasticidades por segmento
    for var in cat_vars:
        formula += f' + C({var}) + {taxa_var}:C({var})'
    
    # Adicionar termo quadr√°tico para capturar n√£o-linearidade
    formula += f' + I({taxa_var}**2)'
    
    print(f"\nüìù F√≥rmula do modelo: {formula}")
    
    # Ajustar modelo
    model = smf.ols(formula=formula, data=train_data).fit()
    
    print("\nüìà SUM√ÅRIO DO MODELO:")
    print(model.summary())
    
    # Fazer previs√µes
    train_data['y_pred'] = model.predict(train_data)
    test_data['y_pred'] = model.predict(test_data)
    
    return model, train_data, test_data

# ==========================================
# 6. C√ÅLCULO DE ELASTICIDADES POR SEGMENTO
# ==========================================

def calculate_segment_elasticities(model, data, taxa_var, cat_vars):
    """
    Calcula elasticidades por segmento
    """
    print("\n" + "="*60)
    print("üíπ ELASTICIDADES POR SEGMENTO")
    print("="*60)
    
    elasticities = {}
    
    # Taxa m√©dia para c√°lculo
    taxa_media = data[taxa_var].mean()
    
    # Elasticidade base (sem segmenta√ß√£o)
    base_elasticity = model.params[taxa_var]
    
    print(f"\nüìä Elasticidade Base: {base_elasticity:.4f}")
    print(f"   Interpreta√ß√£o: Aumento de 1% na taxa ‚Üí {base_elasticity:.2f}% na produ√ß√£o")
    
    # Calcular elasticidade para cada combina√ß√£o de segmentos
    for var in cat_vars:
        elasticities[var] = {}
        categories = data[var].unique()
        
        print(f"\nüìà Elasticidades por {var}:")
        
        for cat in categories:
            # Buscar coeficiente de intera√ß√£o
            interaction_term = f'{taxa_var}:C({var})[T.{cat}]'
            
            if interaction_term in model.params:
                segment_elasticity = base_elasticity + model.params[interaction_term]
            else:
                segment_elasticity = base_elasticity
            
            elasticities[var][cat] = segment_elasticity
            
            # Calcular impacto percentual
            impact = (segment_elasticity * taxa_media) / 100
            
            print(f"   {cat}: {segment_elasticity:.4f} (Impacto de 1pp na taxa: {impact:.2%})")
    
    # Criar DataFrame com elasticidades
    elasticity_df = pd.DataFrame()
    for var in cat_vars:
        temp_df = pd.DataFrame(list(elasticities[var].items()), 
                               columns=['Segmento', 'Elasticidade'])
        temp_df['Vari√°vel'] = var
        elasticity_df = pd.concat([elasticity_df, temp_df], ignore_index=True)
    
    # Visualiza√ß√£o das elasticidades
    fig, axes = plt.subplots(1, len(cat_vars), figsize=(6*len(cat_vars), 5))
    if len(cat_vars) == 1:
        axes = [axes]
    
    for idx, var in enumerate(cat_vars):
        data_plot = elasticity_df[elasticity_df['Vari√°vel'] == var]
        axes[idx].barh(data_plot['Segmento'], data_plot['Elasticidade'])
        axes[idx].set_xlabel('Elasticidade')
        axes[idx].set_title(f'Elasticidade por {var}')
        axes[idx].axvline(x=0, color='r', linestyle='--', alpha=0.5)
        
        # Adicionar valores nas barras
        for i, (seg, elast) in enumerate(zip(data_plot['Segmento'], data_plot['Elasticidade'])):
            axes[idx].text(elast, i, f'{elast:.3f}', va='center')
    
    plt.tight_layout()
    plt.show()
    
    return elasticities

# ==========================================
# 7. DIAGN√ìSTICO DO MODELO
# ==========================================

def model_diagnostics(model, train_data, test_data):
    """
    Realiza diagn√≥sticos completos do modelo
    """
    print("\n" + "="*60)
    print("üîç DIAGN√ìSTICO DO MODELO")
    print("="*60)
    
    # M√©tricas para treino e teste
    datasets = {'Treino': train_data, 'Teste': test_data}
    metrics = {}
    
    for name, data in datasets.items():
        y_true = data['producao_simulacao']
        y_pred = data['y_pred']
        
        mae = mean_absolute_error(y_true, y_pred)
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        r2 = r2_score(y_true, y_pred)
        mape = mean_absolute_percentage_error(y_true, y_pred) * 100
        
        metrics[name] = {
            'MAE': mae,
            'RMSE': rmse,
            'R¬≤': r2,
            'MAPE': mape
        }
        
        print(f"\nüìä M√©tricas - {name}:")
        print(f"   MAE:  R$ {mae:,.2f}")
        print(f"   RMSE: R$ {rmse:,.2f}")
        print(f"   R¬≤:   {r2:.4f}")
        print(f"   MAPE: {mape:.2f}%")
    
    # Plots de diagn√≥stico
    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    
    # 1. Valores preditos vs reais (Treino)
    axes[0, 0].scatter(train_data['producao_simulacao'], train_data['y_pred'], alpha=0.5)
    axes[0, 0].plot([train_data['producao_simulacao'].min(), train_data['producao_simulacao'].max()],
                    [train_data['producao_simulacao'].min(), train_data['producao_simulacao'].max()],
                    'r--', lw=2)
    axes[0, 0].set_xlabel('Valor Real')
    axes[0, 0].set_ylabel('Valor Predito')
    axes[0, 0].set_title(f'Predito vs Real - Treino (R¬≤={metrics["Treino"]["R¬≤"]:.3f})')
    
    # 2. Valores preditos vs reais (Teste)
    axes[0, 1].scatter(test_data['producao_simulacao'], test_data['y_pred'], alpha=0.5, color='orange')
    axes[0, 1].plot([test_data['producao_simulacao'].min(), test_data['producao_simulacao'].max()],
                    [test_data['producao_simulacao'].min(), test_data['producao_simulacao'].max()],
                    'r--', lw=2)
    axes[0, 1].set_xlabel('Valor Real')
    axes[0, 1].set_ylabel('Valor Predito')
    axes[0, 1].set_title(f'Predito vs Real - Teste (R¬≤={metrics["Teste"]["R¬≤"]:.3f})')
    
    # 3. Distribui√ß√£o dos res√≠duos
    train_residuals = train_data['producao_simulacao'] - train_data['y_pred']
    test_residuals = test_data['producao_simulacao'] - test_data['y_pred']
    
    axes[0, 2].hist(train_residuals, bins=30, alpha=0.7, label='Treino', edgecolor='black')
    axes[0, 2].hist(test_residuals, bins=30, alpha=0.7, label='Teste', edgecolor='black')
    axes[0, 2].axvline(x=0, color='r', linestyle='--')
    axes[0, 2].set_xlabel('Res√≠duos')
    axes[0, 2].set_ylabel('Frequ√™ncia')
    axes[0, 2].set_title('Distribui√ß√£o dos Res√≠duos')
    axes[0, 2].legend()
    
    # 4. Q-Q Plot dos res√≠duos
    stats.probplot(train_residuals, dist="norm", plot=axes[1, 0])
    axes[1, 0].set_title('Q-Q Plot - Res√≠duos do Treino')
    
    # 5. Res√≠duos vs Valores Ajustados
    axes[1, 1].scatter(train_data['y_pred'], train_residuals, alpha=0.5)
    axes[1, 1].axhline(y=0, color='r', linestyle='--')
    axes[1, 1].set_xlabel('Valores Ajustados')
    axes[1, 1].set_ylabel('Res√≠duos')
    axes[1, 1].set_title('Res√≠duos vs Valores Ajustados')
    
    # 6. Boxplot dos erros relativos
    train_data['erro_relativo'] = (train_data['y_pred'] - train_data['producao_simulacao']) / train_data['producao_simulacao']
    test_data['erro_relativo'] = (test_data['y_pred'] - test_data['producao_simulacao']) / test_data['producao_simulacao']
    
    box_data = [train_data['erro_relativo'].dropna(), test_data['erro_relativo'].dropna()]
    axes[1, 2].boxplot(box_data, labels=['Treino', 'Teste'])
    axes[1, 2].set_ylabel('Erro Relativo')
    axes[1, 2].set_title('Distribui√ß√£o do Erro Relativo')
    axes[1, 2].axhline(y=0, color='r', linestyle='--', alpha=0.5)
    
    plt.tight_layout()
    plt.show()
    
    # Teste de normalidade dos res√≠duos
    _, p_value = stats.shapiro(train_residuals[:5000] if len(train_residuals) > 5000 else train_residuals)
    print(f"\nüìä Teste de Normalidade dos Res√≠duos (Shapiro-Wilk):")
    print(f"   P-valor: {p_value:.4f}")
    print(f"   Conclus√£o: {'Res√≠duos seguem distribui√ß√£o normal' if p_value > 0.05 else 'Res√≠duos N√ÉO seguem distribui√ß√£o normal'}")
    
    return metrics

# ==========================================
# 8. SIMULA√á√ÉO DE CEN√ÅRIOS
# ==========================================

def simulate_pricing_scenarios(model, base_data, taxa_var, cat_vars):
    """
    Simula diferentes cen√°rios de precifica√ß√£o
    """
    print("\n" + "="*60)
    print("üéØ SIMULA√á√ÉO DE CEN√ÅRIOS DE PRECIFICA√á√ÉO")
    print("="*60)
    
    # Taxa base (m√©dia atual)
    taxa_base = base_data[taxa_var].mean()
    
    # Definir cen√°rios de mudan√ßa na taxa
    scenarios = {
        'Redu√ß√£o Agressiva': -2.0,  # -2 pontos percentuais
        'Redu√ß√£o Moderada': -1.0,   # -1 ponto percentual
        'Redu√ß√£o Leve': -0.5,       # -0.5 ponto percentual
        'Baseline': 0.0,            # Sem mudan√ßa
        'Aumento Leve': 0.5,        # +0.5 ponto percentual
        'Aumento Moderado': 1.0,    # +1 ponto percentual
        'Aumento Agressivo': 2.0    # +2 pontos percentuais
    }
    
    results = []
    
    # Para cada cen√°rio
    for scenario_name, taxa_change in scenarios.items():
        # Criar c√≥pia dos dados
        scenario_data = base_data.copy()
        
        # Aplicar mudan√ßa na taxa
        scenario_data[taxa_var] = scenario_data[taxa_var] + taxa_change
        
        # Prever produ√ß√£o
        scenario_data['y_pred_scenario'] = model.predict(scenario_data)
        
        # Calcular produ√ß√£o total
        prod_total_base = base_data['producao_simulacao'].sum()
        prod_total_scenario = scenario_data['y_pred_scenario'].sum()
        
        # Varia√ß√£o percentual
        var_pct = ((prod_total_scenario - prod_total_base) / prod_total_base) * 100
        
        results.append({
            'Cen√°rio': scenario_name,
            'Œî Taxa (pp)': taxa_change,
            'Taxa M√©dia': taxa_base + taxa_change,
            'Produ√ß√£o Base': prod_total_base,
            'Produ√ß√£o Simulada': prod_total_scenario,
            'Œî Produ√ß√£o': prod_total_scenario - prod_total_base,
            'Œî Produ√ß√£o (%)': var_pct
        })
    
    # DataFrame com resultados
    scenarios_df = pd.DataFrame(results)
    
    print("\nüìä Resultados das Simula√ß√µes:")
    print(scenarios_df.to_string(index=False))
    
    # Visualiza√ß√£o
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))
    
    # 1. Impacto na produ√ß√£o total
    colors = ['red' if x < 0 else 'green' if x > 0 else 'gray' for x in scenarios_df['Œî Produ√ß√£o (%)']]
    axes[0].barh(scenarios_df['Cen√°rio'], scenarios_df['Œî Produ√ß√£o (%)'], color=colors)
    axes[0].axvline(x=0, color='black', linestyle='-', linewidth=0.5)
    axes[0].set_xlabel('Varia√ß√£o na Produ√ß√£o (%)')
    axes[0].set_title('Impacto dos Cen√°rios na Produ√ß√£o Total')
    
    # Adicionar valores nas barras
    for i, (cenario, valor) in enumerate(zip(scenarios_df['Cen√°rio'], scenarios_df['Œî Produ√ß√£o (%)'])):
        axes[0].text(valor, i, f'{valor:.1f}%', va='center', 
                    ha='left' if valor >= 0 else 'right')
    
    # 2. Curva de elasticidade
    taxa_range = np.linspace(taxa_base - 3, taxa_base + 3, 100)
    base_data_sim = base_data.copy()
    producao_sim = []
    
    for t in taxa_range:
        base_data_sim[taxa_var] = t
        pred = model.predict(base_data_sim).sum()
        producao_sim.append(pred)
    
    axes[1].plot(taxa_range, producao_sim, 'b-', linewidth=2)
    axes[1].scatter(scenarios_df['Taxa M√©dia'], 
                   [scenarios_df[scenarios_df['Cen√°rio']==s]['Produ√ß√£o Simulada'].values[0] 
                    for s in scenarios_df['Cen√°rio']], 
                   color='red', s=100, zorder=5)
    axes[1].axvline(x=taxa_base, color='gray', linestyle='--', alpha=0.5, label='Taxa Atual')
    axes[1].set_xlabel('Taxa (%)')
    axes[1].set_ylabel('Produ√ß√£o Total Estimada')
    axes[1].set_title('Curva de Resposta √† Taxa')
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    # An√°lise por segmento (exemplo com UF)
    if 'uf' in cat_vars:
        print("\nüìä Impacto por UF (Cen√°rio: Redu√ß√£o Moderada -1pp):")
        scenario_data = base_data.copy()
        scenario_data[taxa_var] = scenario_data[taxa_var] - 1.0
        scenario_data['y_pred_scenario'] = model.predict(scenario_data)
        
        impact_by_uf = scenario_data.groupby('uf').agg({
            'producao_simulacao': 'sum',
            'y_pred_scenario': 'sum'
        })
        impact_by_uf['Œî (%)'] = ((impact_by_uf['y_pred_scenario'] - impact_by_uf['producao_simulacao']) 
                                 / impact_by_uf['producao_simulacao'] * 100)
        impact_by_uf = impact_by_uf.sort_values('Œî (%)', ascending=False)
        
        print(impact_by_uf[['Œî (%)']].head(10))
    
    return scenarios_df

# ==========================================
# 9. FUN√á√ÉO PRINCIPAL DE EXECU√á√ÉO
# ==========================================

def run_elasticity_analysis(anomes_treino, anomes_teste):
    """
    Executa an√°lise completa de elasticidade
    
    Parameters:
    anomes_treino: lista de per√≠odos para treino (ex: [202501, 202502, 202503])
    anomes_teste: lista de per√≠odos para teste (ex: [202504])
    """
    
    print("="*60)
    print("üöÄ MODELO DE ELASTICIDADE - FINANCIAMENTO DE VE√çCULOS")
    print("="*60)
    print(f"üìÖ Per√≠odos de Treino: {anomes_treino}")
    print(f"üìÖ Per√≠odos de Teste: {anomes_teste}")
    
    # Definir vari√°veis
    prod_var = 'valor_prod'
    taxa_var = 'pct_txa_ofrt_simu_pmro_vers'
    cat_vars = ['uf', 'rating_price', 'seg_cliente']
    
    # 1. Carregar dados
    all_periods = anomes_treino + anomes_teste
    df = load_and_prepare_data(all_periods)
    
    # 2. An√°lise explorat√≥ria
    perform_eda(df, prod_var, taxa_var, cat_vars)
    
    # 3. An√°lise de import√¢ncia das features
    importance_df = analyze_feature_importance(df, prod_var, taxa_var, cat_vars)
    
    # 4. Preparar dados para modelagem
    train_data, test_data = prepare_modeling_data(
        df, prod_var, taxa_var, cat_vars, anomes_treino, anomes_teste
    )
    
    # 5. Construir modelo
    model, train_data, test_data = build_elasticity_model(
        train_data, test_data, prod_var, taxa_var, cat_vars
    )
    
    # 6. Calcular elasticidades por segmento
    elasticities = calculate_segment_elasticities(
        model, train_data, taxa_var, cat_vars
    )
    
    # 7. Diagn√≥stico do modelo
    metrics = model_diagnostics(model, train_data, test_data)
    
    # 8. Simular cen√°rios
    scenarios_df = simulate_pricing_scenarios(
        model, train_data, taxa_var, cat_vars
    )
    
    print("\n" + "="*60)
    print("‚úÖ AN√ÅLISE CONCLU√çDA COM SUCESSO!")
    print("="*60)
    
    return {
        'model': model,
        'train_data': train_data,
        'test_data': test_data,
        'elasticities': elasticities,
        'metrics': metrics,
        'scenarios': scenarios_df
    }

# ==========================================
# EXECU√á√ÉO
# ==========================================

if __name__ == "__main__":
    # Definir per√≠odos de an√°lise
    ANOMES_TREINO = [202501, 202502, 202503]  # Janeiro a Mar√ßo 2025
    ANOMES_TESTE = [202504]                   # Abril 2025
    
    # Executar an√°lise completa
    results = run_elasticity_analysis(ANOMES_TREINO, ANOMES_TESTE)
    
    # Os resultados podem ser acessados atrav√©s do dicion√°rio 'results'
    # results['model'] - modelo treinado
    # results['elasticities'] - elasticidades por segmento
    # results['metrics'] - m√©tricas de performance
    # results['scenarios'] - cen√°rios simulados
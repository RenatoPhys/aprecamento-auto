"""
Modelo de Elasticidade de Demanda - Financiamento de Ve√≠culos
An√°lise completa de elasticidade-pre√ßo e simula√ß√£o de cen√°rios
Com vari√°veis categ√≥ricas parametriz√°veis
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from datetime import datetime
from typing import List, Dict, Tuple, Optional

# Bibliotecas para modelagem
import statsmodels.formula.api as smf
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error
from sklearn.preprocessing import StandardScaler
from scipy import stats

warnings.filterwarnings('ignore')

# Configura√ß√£o de visualiza√ß√£o
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# ==========================================
# CONFIGURA√á√ÉO DAS VARI√ÅVEIS DISPON√çVEIS
# ==========================================

# Lista de todas as vari√°veis categ√≥ricas dispon√≠veis no dataset
AVAILABLE_CATEGORICAL_VARS = [
    'uf',                    # Unidade Federativa
    'rating_price',          # Rating de pre√ßo
    'seg_cliente',           # Segmento de cliente
    'tipo_veiculo',          # Tipo de ve√≠culo (se dispon√≠vel)
    'canal_venda',           # Canal de venda (se dispon√≠vel)
    'regiao',               # Regi√£o geogr√°fica (se dispon√≠vel)
    'faixa_financiamento',   # Faixa de valor financiado (se dispon√≠vel)
]

# Configura√ß√µes padr√£o
DEFAULT_CAT_VARS = ['uf', 'rating_price', 'seg_cliente']
DEFAULT_PROD_VAR = 'valor_prod'
DEFAULT_TAXA_VAR = 'pct_txa_ofrt_simu_pmro_vers'

# ==========================================
# 1. VALIDA√á√ÉO E PREPARA√á√ÉO DAS VARI√ÅVEIS
# ==========================================

def validate_categorical_vars(df: pd.DataFrame, 
                            requested_vars: List[str], 
                            min_categories: int = 2,
                            max_categories: int = 50) -> List[str]:
    """
    Valida e filtra as vari√°veis categ√≥ricas solicitadas
    
    Parameters:
    -----------
    df : pd.DataFrame
        DataFrame com os dados
    requested_vars : List[str]
        Lista de vari√°veis categ√≥ricas desejadas
    min_categories : int
        N√∫mero m√≠nimo de categorias √∫nicas para considerar a vari√°vel
    max_categories : int
        N√∫mero m√°ximo de categorias √∫nicas para considerar a vari√°vel
    
    Returns:
    --------
    List[str]: Lista de vari√°veis categ√≥ricas validadas
    """
    print("\n" + "="*60)
    print("üîç VALIDA√á√ÉO DAS VARI√ÅVEIS CATEG√ìRICAS")
    print("="*60)
    
    validated_vars = []
    
    for var in requested_vars:
        # Verificar se a vari√°vel existe no dataset
        if var not in df.columns:
            print(f"‚ö†Ô∏è  Vari√°vel '{var}' n√£o encontrada no dataset")
            continue
        
        # Verificar n√∫mero de categorias √∫nicas
        n_unique = df[var].nunique()
        
        if n_unique < min_categories:
            print(f"‚ö†Ô∏è  Vari√°vel '{var}' tem apenas {n_unique} categoria(s) - ignorada")
            continue
        
        if n_unique > max_categories:
            print(f"‚ö†Ô∏è  Vari√°vel '{var}' tem {n_unique} categorias - muito alta cardinalidade")
            # Perguntar se deseja continuar ou criar faixas
            print(f"    Considerando apenas as top {max_categories} categorias")
            # Voc√™ pode implementar l√≥gica para agrupar categorias menos frequentes
        
        # Verificar valores nulos
        null_pct = df[var].isnull().sum() / len(df) * 100
        if null_pct > 50:
            print(f"‚ö†Ô∏è  Vari√°vel '{var}' tem {null_pct:.1f}% de valores nulos - ignorada")
            continue
        
        validated_vars.append(var)
        print(f"‚úÖ Vari√°vel '{var}' validada: {n_unique} categorias, {null_pct:.1f}% nulos")
    
    if not validated_vars:
        print("‚ö†Ô∏è  Nenhuma vari√°vel categ√≥rica v√°lida encontrada!")
        print("    Usando vari√°veis padr√£o dispon√≠veis...")
        # Tentar usar vari√°veis padr√£o
        for var in DEFAULT_CAT_VARS:
            if var in df.columns and df[var].nunique() >= min_categories:
                validated_vars.append(var)
                print(f"‚úÖ Vari√°vel padr√£o '{var}' adicionada")
    
    print(f"\nüìä Vari√°veis categ√≥ricas finais: {validated_vars}")
    return validated_vars

# ==========================================
# 2. CARREGAMENTO E PREPARA√á√ÉO DOS DADOS
# ==========================================

def load_and_prepare_data(anomes_list: List[int]) -> pd.DataFrame:
    """
    Carrega e prepara os dados para modelagem
    
    Parameters:
    -----------
    anomes_list : List[int]
        Lista com os per√≠odos a serem analisados
    
    Returns:
    --------
    pd.DataFrame: DataFrame preparado
    """
    
    # Query parametrizada
    anomes_str = ','.join([str(x) for x in anomes_list])
    query = f'''
        SELECT *
        FROM tb_funil_veiculos
        WHERE anomes IN ({anomes_str})
    '''
    
    # Carregamento dos dados
    print(f"üìä Carregando dados dos per√≠odos: {anomes_str}")
    df = wr.athena.read_sql(query)
    
    # Convers√£o de tipos
    df['pct_txa_ofrt_simu_pmro_vers'] = df['pct_txa_ofrt_simu_pmro_vers'].astype(float)
    df['valor_prod'] = df['valor_prod'].astype(float)
    
    # Cria√ß√£o de features adicionais
    df['log_valor_prod'] = np.log1p(df['valor_prod'])
    df['taxa_squared'] = df['pct_txa_ofrt_simu_pmro_vers'] ** 2
    
    print(f"‚úÖ Dados carregados: {df.shape[0]:,} registros")
    print(f"üìÖ Per√≠odos dispon√≠veis: {df['anomes'].unique()}")
    
    return df

# ==========================================
# 3. AN√ÅLISE EXPLORAT√ìRIA ADAPTATIVA
# ==========================================

def perform_eda(df: pd.DataFrame, 
                prod_var: str, 
                taxa_var: str, 
                cat_vars: List[str]) -> None:
    """
    Realiza an√°lise explorat√≥ria dos dados adaptada √†s vari√°veis categ√≥ricas
    """
    print("\n" + "="*60)
    print("üìà AN√ÅLISE EXPLORAT√ìRIA DOS DADOS")
    print("="*60)
    
    # Estat√≠sticas descritivas
    print("\nüìä Estat√≠sticas da Taxa de Juros:")
    print(df[taxa_var].describe())
    
    print("\nüìä Estat√≠sticas da Produ√ß√£o:")
    print(df[prod_var].describe())
    
    # Ajustar n√∫mero de subplots baseado nas vari√°veis dispon√≠veis
    n_cat_vars = len(cat_vars)
    n_plots = 3 + min(n_cat_vars, 3)  # Plots b√°sicos + plots por categoria (m√°x 3)
    
    # Calcular layout da figura
    n_cols = 3
    n_rows = (n_plots + n_cols - 1) // n_cols
    
    fig = plt.figure(figsize=(20, 6 * n_rows))
    
    plot_idx = 1
    
    # 1. Distribui√ß√£o da Taxa
    ax = plt.subplot(n_rows, n_cols, plot_idx)
    df[taxa_var].hist(bins=50, edgecolor='black', alpha=0.7, ax=ax)
    ax.axvline(df[taxa_var].mean(), color='red', linestyle='--', 
               label=f'M√©dia: {df[taxa_var].mean():.2f}%')
    ax.set_xlabel('Taxa (%)')
    ax.set_ylabel('Frequ√™ncia')
    ax.set_title('Distribui√ß√£o da Taxa de Juros')
    ax.legend()
    plot_idx += 1
    
    # 2. Distribui√ß√£o da Produ√ß√£o
    ax = plt.subplot(n_rows, n_cols, plot_idx)
    df[prod_var].hist(bins=50, edgecolor='black', alpha=0.7, ax=ax)
    ax.axvline(df[prod_var].mean(), color='red', linestyle='--', 
               label=f'M√©dia: R$ {df[prod_var].mean():,.0f}')
    ax.set_xlabel('Valor Produzido (R$)')
    ax.set_ylabel('Frequ√™ncia')
    ax.set_title('Distribui√ß√£o da Produ√ß√£o')
    ax.legend()
    plot_idx += 1
    
    # 3. Scatter plot Taxa vs Produ√ß√£o
    ax = plt.subplot(n_rows, n_cols, plot_idx)
    ax.scatter(df[taxa_var], df[prod_var], alpha=0.5, s=10)
    z = np.polyfit(df[taxa_var], df[prod_var], 1)
    p = np.poly1d(z)
    ax.plot(df[taxa_var].sort_values(), p(df[taxa_var].sort_values()), 
            "r--", alpha=0.8, label='Tend√™ncia Linear')
    ax.set_xlabel('Taxa (%)')
    ax.set_ylabel('Valor Produzido (R$)')
    ax.set_title('Rela√ß√£o Taxa vs Produ√ß√£o')
    ax.legend()
    plot_idx += 1
    
    # Plots espec√≠ficos para cada vari√°vel categ√≥rica (at√© 3)
    for i, var in enumerate(cat_vars[:3]):
        if plot_idx > n_rows * n_cols:
            break
            
        ax = plt.subplot(n_rows, n_cols, plot_idx)
        
        # Decidir tipo de plot baseado no n√∫mero de categorias
        n_categories = df[var].nunique()
        
        if n_categories <= 10:
            # Boxplot para poucas categorias
            df.boxplot(column=taxa_var, by=var, ax=ax, rot=45)
            plt.suptitle('')
            ax.set_title(f'Taxa por {var}')
            ax.set_xlabel(var)
            ax.set_ylabel('Taxa (%)')
        else:
            # Barplot com top 10 categorias para muitas categorias
            top_cats = df.groupby(var)[prod_var].mean().nlargest(10)
            top_cats.plot(kind='bar', ax=ax)
            ax.set_title(f'Top 10 {var} por Produ√ß√£o M√©dia')
            ax.set_xlabel(var)
            ax.set_ylabel('Produ√ß√£o M√©dia (R$)')
            plt.xticks(rotation=45, ha='right')
        
        plot_idx += 1
    
    plt.tight_layout()
    plt.show()
    
    # An√°lise por per√≠odo
    print("\nüìÖ An√°lise por Per√≠odo (anomes):")
    period_analysis = df.groupby('anomes').agg({
        prod_var: ['count', 'mean', 'sum'],
        taxa_var: ['mean', 'std']
    }).round(2)
    print(period_analysis)
    
    # An√°lise por vari√°vel categ√≥rica
    for var in cat_vars:
        print(f"\nüìä An√°lise por {var}:")
        var_analysis = df.groupby(var).agg({
            prod_var: ['count', 'mean', 'sum'],
            taxa_var: ['mean', 'std']
        }).round(2)
        print(var_analysis.head(10))

# ==========================================
# 4. PREPARA√á√ÉO PARA MODELAGEM FLEX√çVEL
# ==========================================

def prepare_modeling_data(df: pd.DataFrame, 
                         prod_var: str, 
                         taxa_var: str, 
                         cat_vars: List[str], 
                         train_periods: List[int], 
                         test_periods: List[int]) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    Prepara os dados para treino e teste com vari√°veis categ√≥ricas flex√≠veis
    """
    print("\n" + "="*60)
    print("üîß PREPARA√á√ÉO DOS DADOS PARA MODELAGEM")
    print("="*60)
    
    # Criar range de taxa
    df['range_taxa'] = pd.qcut(df[taxa_var], q=5)
    
    # Definir colunas de agrupamento dinamicamente
    groupby_cols = cat_vars + ['range_taxa', 'anomes']
    
    # Agrega√ß√£o dos dados
    agg_dict = {
        'qtd_obs': (prod_var, 'count'),
        'taxa_media': (taxa_var, 'mean'),
        'producao_simulacao': (prod_var, 'mean'),
        'producao_total': (prod_var, 'sum')
    }
    
    aux = df.groupby(groupby_cols, observed=True).agg(**agg_dict).reset_index()
    
    # Renomear coluna de taxa
    aux.rename(columns={'taxa_media': taxa_var}, inplace=True)
    
    # Separar treino e teste por per√≠odo
    train_data = aux[aux['anomes'].isin(train_periods)].copy()
    test_data = aux[aux['anomes'].isin(test_periods)].copy()
    
    print(f"üìä Dados de Treino: {len(train_data)} registros (per√≠odos: {train_periods})")
    print(f"üìä Dados de Teste: {len(test_data)} registros (per√≠odos: {test_periods})")
    print(f"üìä Vari√°veis categ√≥ricas utilizadas: {cat_vars}")
    
    # Converter vari√°veis categ√≥ricas
    for var in cat_vars:
        if var in train_data.columns:
            train_data[var] = train_data[var].astype('category')
        if var in test_data.columns:
            test_data[var] = test_data[var].astype('category')
    
    return train_data, test_data

# ==========================================
# 5. MODELAGEM COM F√ìRMULA DIN√ÇMICA
# ==========================================

def build_elasticity_model(train_data: pd.DataFrame, 
                          test_data: pd.DataFrame, 
                          prod_var: str, 
                          taxa_var: str, 
                          cat_vars: List[str],
                          include_interactions: bool = True,
                          include_quadratic: bool = True) -> Tuple:
    """
    Constr√≥i modelo de elasticidade com f√≥rmula din√¢mica
    
    Parameters:
    -----------
    include_interactions : bool
        Se True, inclui intera√ß√µes entre taxa e vari√°veis categ√≥ricas
    include_quadratic : bool
        Se True, inclui termo quadr√°tico da taxa
    """
    print("\n" + "="*60)
    print("üìä CONSTRU√á√ÉO DO MODELO DE ELASTICIDADE")
    print("="*60)
    
    # Vari√°vel dependente
    y = 'producao_simulacao'
    
    # Construir f√≥rmula do modelo dinamicamente
    formula_parts = [y, '~', taxa_var]
    
    # Adicionar vari√°veis categ√≥ricas e intera√ß√µes se solicitado
    if cat_vars:
        for var in cat_vars:
            formula_parts.append(f' + C({var})')
            if include_interactions:
                formula_parts.append(f' + {taxa_var}:C({var})')
    
    # Adicionar termo quadr√°tico se solicitado
    if include_quadratic:
        formula_parts.append(f' + I({taxa_var}**2)')
    
    formula = ''.join(formula_parts)
    
    print(f"\nüìù F√≥rmula do modelo: {formula}")
    print(f"   - Vari√°veis categ√≥ricas: {cat_vars if cat_vars else 'Nenhuma'}")
    print(f"   - Intera√ß√µes: {'Sim' if include_interactions and cat_vars else 'N√£o'}")
    print(f"   - Termo quadr√°tico: {'Sim' if include_quadratic else 'N√£o'}")
    
    # Ajustar modelo
    try:
        model = smf.ols(formula=formula, data=train_data).fit()
        
        print("\nüìà SUM√ÅRIO DO MODELO:")
        print(model.summary())
        
        # Fazer previs√µes
        train_data['y_pred'] = model.predict(train_data)
        test_data['y_pred'] = model.predict(test_data)
        
        return model, train_data, test_data
        
    except Exception as e:
        print(f"‚ùå Erro ao ajustar modelo: {e}")
        print("    Tentando modelo simplificado...")
        
        # Modelo simplificado sem intera√ß√µes
        simple_formula = f'{y} ~ {taxa_var}'
        if cat_vars:
            for var in cat_vars:
                simple_formula += f' + C({var})'
        
        model = smf.ols(formula=simple_formula, data=train_data).fit()
        
        print("\nüìà SUM√ÅRIO DO MODELO SIMPLIFICADO:")
        print(model.summary())
        
        train_data['y_pred'] = model.predict(train_data)
        test_data['y_pred'] = model.predict(test_data)
        
        return model, train_data, test_data

# ==========================================
# 6. C√ÅLCULO DE ELASTICIDADES DIN√ÇMICO
# ==========================================

def calculate_segment_elasticities(model, 
                                  data: pd.DataFrame, 
                                  taxa_var: str, 
                                  cat_vars: List[str]) -> Dict:
    """
    Calcula elasticidades por segmento de forma din√¢mica
    """
    print("\n" + "="*60)
    print("üíπ ELASTICIDADES POR SEGMENTO")
    print("="*60)
    
    elasticities = {}
    
    # Taxa m√©dia para c√°lculo
    taxa_media = data[taxa_var].mean()
    
    # Elasticidade base (sem segmenta√ß√£o)
    base_elasticity = model.params.get(taxa_var, 0)
    
    print(f"\nüìä Elasticidade Base: {base_elasticity:.4f}")
    print(f"   Interpreta√ß√£o: Aumento de 1% na taxa ‚Üí {base_elasticity:.2f}% na produ√ß√£o")
    
    if not cat_vars:
        print("\n‚ö†Ô∏è  Sem vari√°veis categ√≥ricas para segmenta√ß√£o")
        return {'base': base_elasticity}
    
    # Calcular elasticidade para cada vari√°vel categ√≥rica
    for var in cat_vars:
        elasticities[var] = {}
        categories = data[var].unique()
        
        print(f"\nüìà Elasticidades por {var}:")
        
        for cat in categories:
            # Buscar coeficiente de intera√ß√£o
            interaction_term = f'{taxa_var}:C({var})[T.{cat}]'
            
            if interaction_term in model.params:
                segment_elasticity = base_elasticity + model.params[interaction_term]
            else:
                segment_elasticity = base_elasticity
            
            elasticities[var][cat] = segment_elasticity
            
            # Calcular impacto percentual
            impact = (segment_elasticity * taxa_media) / 100
            
            print(f"   {cat}: {segment_elasticity:.4f} (Impacto de 1pp na taxa: {impact:.2%})")
    
    # Criar DataFrame com elasticidades
    elasticity_df = pd.DataFrame()
    for var in cat_vars:
        temp_df = pd.DataFrame(list(elasticities[var].items()), 
                               columns=['Segmento', 'Elasticidade'])
        temp_df['Vari√°vel'] = var
        elasticity_df = pd.concat([elasticity_df, temp_df], ignore_index=True)
    
    # Visualiza√ß√£o das elasticidades (adaptativa ao n√∫mero de vari√°veis)
    n_vars = len(cat_vars)
    if n_vars > 0:
        fig, axes = plt.subplots(1, min(n_vars, 3), figsize=(6*min(n_vars, 3), 5))
        if n_vars == 1:
            axes = [axes]
        
        for idx, var in enumerate(cat_vars[:3]):  # Mostrar no m√°ximo 3
            data_plot = elasticity_df[elasticity_df['Vari√°vel'] == var]
            axes[idx].barh(data_plot['Segmento'], data_plot['Elasticidade'])
            axes[idx].set_xlabel('Elasticidade')
            axes[idx].set_title(f'Elasticidade por {var}')
            axes[idx].axvline(x=0, color='r', linestyle='--', alpha=0.5)
            
            # Adicionar valores nas barras
            for i, (seg, elast) in enumerate(zip(data_plot['Segmento'], data_plot['Elasticidade'])):
                axes[idx].text(elast, i, f'{elast:.3f}', va='center')
        
        plt.tight_layout()
        plt.show()
    
    return elasticities

# ==========================================
# 7. AN√ÅLISE DE IMPORT√ÇNCIA DAS FEATURES
# ==========================================

def analyze_feature_importance(df: pd.DataFrame, 
                              prod_var: str, 
                              taxa_var: str, 
                              cat_vars: List[str]) -> pd.DataFrame:
    """
    Analisa a import√¢ncia das features para o modelo
    """
    print("\n" + "="*60)
    print("üîç AN√ÅLISE DE IMPORT√ÇNCIA DAS FEATURES")
    print("="*60)
    
    # Criar dataframe agregado
    df['range_taxa'] = pd.qcut(df[taxa_var], q=5, labels=['Muito Baixa', 'Baixa', 'M√©dia', 'Alta', 'Muito Alta'])
    
    results = []
    
    # An√°lise univariada para cada vari√°vel categ√≥rica
    for var in cat_vars:
        try:
            # Calcular produ√ß√£o m√©dia por categoria
            prod_by_cat = df.groupby(var)[prod_var].agg(['mean', 'std', 'count'])
            
            # ANOVA para testar signific√¢ncia
            groups = [group[prod_var].values for name, group in df.groupby(var)]
            if len(groups) > 1:  # Precisa de pelo menos 2 grupos
                f_stat, p_value = stats.f_oneway(*groups)
            else:
                f_stat, p_value = 0, 1
            
            # Coeficiente de varia√ß√£o
            cv = prod_by_cat['std'].mean() / prod_by_cat['mean'].mean() if prod_by_cat['mean'].mean() != 0 else 0
            
            results.append({
                'Vari√°vel': var,
                'Categorias': df[var].nunique(),
                'F-statistic': f_stat,
                'P-value': p_value,
                'Coef. Varia√ß√£o': cv,
                'Significante': 'Sim' if p_value < 0.05 else 'N√£o'
            })
        except Exception as e:
            print(f"‚ö†Ô∏è  Erro ao analisar {var}: {e}")
            continue
    
    if not results:
        print("‚ö†Ô∏è  Nenhuma an√°lise de import√¢ncia dispon√≠vel")
        return pd.DataFrame()
    
    # DataFrame com resultados
    importance_df = pd.DataFrame(results)
    importance_df = importance_df.sort_values('F-statistic', ascending=False)
    
    print("\nüìä Import√¢ncia das Vari√°veis Categ√≥ricas (ANOVA):")
    print(importance_df.to_string(index=False))
    
    # Visualiza√ß√£o
    if len(importance_df) > 0:
        fig, axes = plt.subplots(1, 2, figsize=(15, 5))
        
        # F-statistics
        axes[0].barh(importance_df['Vari√°vel'], importance_df['F-statistic'])
        axes[0].set_xlabel('F-statistic')
        axes[0].set_title('Import√¢ncia das Features (F-statistic)')
        axes[0].invert_yaxis()
        
        # P-values
        axes[1].barh(importance_df['Vari√°vel'], -np.log10(importance_df['P-value'] + 1e-10))
        axes[1].axvline(x=-np.log10(0.05), color='r', linestyle='--', label='p=0.05')
        axes[1].set_xlabel('-log10(P-value)')
        axes[1].set_title('Signific√¢ncia Estat√≠stica das Features')
        axes[1].legend()
        axes[1].invert_yaxis()
        
        plt.tight_layout()
        plt.show()
    
    return importance_df

# ==========================================
# 8. DIAGN√ìSTICO DO MODELO
# ==========================================

def model_diagnostics(model, 
                     train_data: pd.DataFrame, 
                     test_data: pd.DataFrame) -> Dict:
    """
    Realiza diagn√≥sticos completos do modelo
    """
    print("\n" + "="*60)
    print("üîç DIAGN√ìSTICO DO MODELO")
    print("="*60)
    
    # M√©tricas para treino e teste
    datasets = {'Treino': train_data, 'Teste': test_data}
    metrics = {}
    
    for name, data in datasets.items():
        y_true = data['producao_simulacao']
        y_pred = data['y_pred']
        
        mae = mean_absolute_error(y_true, y_pred)
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        r2 = r2_score(y_true, y_pred)
        
        # MAPE com tratamento de zeros
        mask = y_true != 0
        if mask.sum() > 0:
            mape = mean_absolute_percentage_error(y_true[mask], y_pred[mask]) * 100
        else:
            mape = np.nan
        
        metrics[name] = {
            'MAE': mae,
            'RMSE': rmse,
            'R¬≤': r2,
            'MAPE': mape
        }
        
        print(f"\nüìä M√©tricas - {name}:")
        print(f"   MAE:  R$ {mae:,.2f}")
        print(f"   RMSE: R$ {rmse:,.2f}")
        print(f"   R¬≤:   {r2:.4f}")
        if not np.isnan(mape):
            print(f"   MAPE: {mape:.2f}%")
    
    # Plots de diagn√≥stico
    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    
    # 1. Valores preditos vs reais (Treino)
    axes[0, 0].scatter(train_data['producao_simulacao'], train_data['y_pred'], alpha=0.5)
    axes[0, 0].plot([train_data['producao_simulacao'].min(), train_data['producao_simulacao'].max()],
                    [train_data['producao_simulacao'].min(), train_data['producao_simulacao'].max()],
                    'r--', lw=2)
    axes[0, 0].set_xlabel('Valor Real')
    axes[0, 0].set_ylabel('Valor Predito')
    axes[0, 0].set_title(f'Predito vs Real - Treino (R¬≤={metrics["Treino"]["R¬≤"]:.3f})')
    
    # 2. Valores preditos vs reais (Teste)
    axes[0, 1].scatter(test_data['producao_simulacao'], test_data['y_pred'], alpha=0.5, color='orange')
    axes[0, 1].plot([test_data['producao_simulacao'].min(), test_data['producao_simulacao'].max()],
                    [test_data['producao_simulacao'].min(), test_data['producao_simulacao'].max()],
                    'r--', lw=2)
    axes[0, 1].set_xlabel('Valor Real')
    axes[0, 1].set_ylabel('Valor Predito')
    axes[0, 1].set_title(f'Predito vs Real - Teste (R¬≤={metrics["Teste"]["R¬≤"]:.3f})')
    
    # 3. Distribui√ß√£o dos res√≠duos
    train_residuals = train_data['producao_simulacao'] - train_data['y_pred']
    test_residuals = test_data['producao_simulacao'] - test_data['y_pred']
    
    axes[0, 2].hist(train_residuals, bins=30, alpha=0.7, label='Treino', edgecolor='black')
    axes[0, 2].hist(test_residuals, bins=30, alpha=0.7, label='Teste', edgecolor='black')
    axes[0, 2].axvline(x=0, color='r', linestyle='--')
    axes[0, 2].set_xlabel('Res√≠duos')
    axes[0, 2].set_ylabel('Frequ√™ncia')
    axes[0, 2].set_title('Distribui√ß√£o dos Res√≠duos')
    axes[0, 2].legend()
    
    # 4. Q-Q Plot dos res√≠duos
    stats.probplot(train_residuals, dist="norm", plot=axes[1, 0])
    axes[1, 0].set_title('Q-Q Plot - Res√≠duos do Treino')
    
    # 5. Res√≠duos vs Valores Ajustados
    axes[1, 1].scatter(train_data['y_pred'], train_residuals, alpha=0.5)
    axes[1, 1].axhline(y=0, color='r', linestyle='--')
    axes[1, 1].set_xlabel('Valores Ajustados')
    axes[1, 1].set_ylabel('Res√≠duos')
    axes[1, 1].set_title('Res√≠duos vs Valores Ajustados')
    
    # 6. Boxplot dos erros relativos
    train_data['erro_relativo'] = np.where(
        train_data['producao_simulacao'] != 0,
        (train_data['y_pred'] - train_data['producao_simulacao']) / train_data['producao_simulacao'],
        np.nan
    )
    test_data['erro_relativo'] = np.where(
        test_data['producao_simulacao'] != 0,
        (test_data['y_pred'] - test_data['producao_simulacao']) / test_data['producao_simulacao'],
        np.nan
    )
    
    box_data = [train_data['erro_relativo'].dropna(), test_data['erro_relativo'].dropna()]
    if all(len(d) > 0 for d in box_data):
        axes[1, 2].boxplot(box_data, labels=['Treino', 'Teste'])
        axes[1, 2].set_ylabel('Erro Relativo')
        axes[1, 2].set_title('Distribui√ß√£o do Erro Relativo')
        axes[1, 2].axhline(y=0, color='r', linestyle='--', alpha=0.5)
    
    plt.tight_layout()
    plt.show()
    
    # Teste de normalidade dos res√≠duos
    if len(train_residuals) > 0:
        sample_size = min(5000, len(train_residuals))
        _, p_value = stats.shapiro(train_residuals[:sample_size])
        print(f"\nüìä Teste de Normalidade dos Res√≠duos (Shapiro-Wilk):")
        print(f"   P-valor: {p_value:.4f}")
        print(f"   Conclus√£o: {'Res√≠duos seguem distribui√ß√£o normal' if p_value > 0.05 else 'Res√≠duos N√ÉO seguem distribui√ß√£o normal'}")
    
    return metrics

# ==========================================
# 9. SIMULA√á√ÉO DE CEN√ÅRIOS
# ==========================================

def simulate_pricing_scenarios(model, 
                              base_data: pd.DataFrame, 
                              taxa_var: str, 
                              cat_vars: List[str]) -> pd.DataFrame:
    """
    Simula diferentes cen√°rios de precifica√ß√£o
    """
    print("\n" + "="*60)
    print("üéØ SIMULA√á√ÉO DE CEN√ÅRIOS DE PRECIFICA√á√ÉO")
    print("="*60)
    
    # Taxa base (m√©dia atual)
    taxa_base = base_data[taxa_var].mean()
    
    # Definir cen√°rios de mudan√ßa na taxa
    scenarios = {
        'Redu√ß√£o Agressiva': -2.0,  # -2 pontos percentuais
        'Redu√ß√£o Moderada': -1.0,   # -1 ponto percentual
        'Redu√ß√£o Leve': -0.5,       # -0.5 ponto percentual
        'Baseline': 0.0,            # Sem mudan√ßa
        'Aumento Leve': 0.5,        # +0.5 ponto percentual
        'Aumento Moderado': 1.0,    # +1 ponto percentual
        'Aumento Agressivo': 2.0    # +2 pontos percentuais
    }
    
    results = []
    
    # Para cada cen√°rio
    for scenario_name, taxa_change in scenarios.items():
        # Criar c√≥pia dos dados
        scenario_data = base_data.copy()
        
        # Aplicar mudan√ßa na taxa
        scenario_data[taxa_var] = scenario_data[taxa_var] + taxa_change
        
        # Prever produ√ß√£o
        scenario_data['y_pred_scenario'] = model.predict(scenario_data)
        
        # Calcular produ√ß√£o total
        prod_total_base = base_data['producao_simulacao'].sum()
        prod_total_scenario = scenario_data['y_pred_scenario'].sum()
        
        # Varia√ß√£o percentual
        var_pct = ((prod_total_scenario - prod_total_base) / prod_total_base) * 100 if prod_total_base != 0 else 0
        
        results.append({
            'Cen√°rio': scenario_name,
            'Œî Taxa (pp)': taxa_change,
            'Taxa M√©dia': taxa_base + taxa_change,
            'Produ√ß√£o Base': prod_total_base,
            'Produ√ß√£o Simulada': prod_total_scenario,
            'Œî Produ√ß√£o': prod_total_scenario - prod_total_base,
            'Œî Produ√ß√£o (%)': var_pct
        })
    
    # DataFrame com resultados
    scenarios_df = pd.DataFrame(results)
    
    print("\nüìä Resultados das Simula√ß√µes:")
    print(scenarios_df.to_string(index=False))
    
    # Visualiza√ß√£o
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))
    
    # 1. Impacto na produ√ß√£o total
    colors = ['red' if x < 0 else 'green' if x > 0 else 'gray' for x in scenarios_df['Œî Produ√ß√£o (%)']]
    axes[0].barh(scenarios_df['Cen√°rio'], scenarios_df['Œî Produ√ß√£o (%)'], color=colors)
    axes[0].axvline(x=0, color='black', linestyle='-', linewidth=0.5)
    axes[0].set_xlabel('Varia√ß√£o na Produ√ß√£o (%)')
    axes[0].set_title('Impacto dos Cen√°rios na Produ√ß√£o Total')
    
    # Adicionar valores nas barras
    for i, (cenario, valor) in enumerate(zip(scenarios_df['Cen√°rio'], scenarios_df['Œî Produ√ß√£o (%)'])):
        axes[0].text(valor, i, f'{valor:.1f}%', va='center', 
                    ha='left' if valor >= 0 else 'right')
    
    # 2. Curva de elasticidade
    taxa_range = np.linspace(max(0, taxa_base - 3), taxa_base + 3, 100)
    base_data_sim = base_data.copy()
    producao_sim = []
    
    for t in taxa_range:
        base_data_sim[taxa_var] = t
        pred = model.predict(base_data_sim).sum()
        producao_sim.append(pred)
    
    axes[1].plot(taxa_range, producao_sim, 'b-', linewidth=2)
    axes[1].scatter(scenarios_df['Taxa M√©dia'], 
                   [scenarios_df[scenarios_df['Cen√°rio']==s]['Produ√ß√£o Simulada'].values[0] 
                    for s in scenarios_df['Cen√°rio']], 
                   color='red', s=100, zorder=5)
    axes[1].axvline(x=taxa_base, color='gray', linestyle='--', alpha=0.5, label='Taxa Atual')
    axes[1].set_xlabel('Taxa (%)')
    axes[1].set_ylabel('Produ√ß√£o Total Estimada')
    axes[1].set_title('Curva de Resposta √† Taxa')
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    # An√°lise por segmento (se houver vari√°veis categ√≥ricas)
    if cat_vars and 'uf' in cat_vars:
        print("\nüìä Impacto por UF (Cen√°rio: Redu√ß√£o Moderada -1pp):")
        scenario_data = base_data.copy()
        scenario_data[taxa_var] = scenario_data[taxa_var] - 1.0
        scenario_data['y_pred_scenario'] = model.predict(scenario_data)
        
        impact_by_uf = scenario_data.groupby('uf').agg({
            'producao_simulacao': 'sum',
            'y_pred_scenario': 'sum'
        })
        impact_by_uf['Œî (%)'] = np.where(
            impact_by_uf['producao_simulacao'] != 0,
            ((impact_by_uf['y_pred_scenario'] - impact_by_uf['producao_simulacao']) 
             / impact_by_uf['producao_simulacao'] * 100),
            0
        )
        impact_by_uf = impact_by_uf.sort_values('Œî (%)', ascending=False)
        
        print(impact_by_uf[['Œî (%)']].head(10))
    
    return scenarios_df

# ==========================================
# 10. FUN√á√ÉO PRINCIPAL DE EXECU√á√ÉO
# ==========================================

def run_elasticity_analysis(anomes_treino: List[int], 
                          anomes_teste: List[int],
                          categorical_vars: Optional[List[str]] = None,
                          prod_var: Optional[str] = None,
                          taxa_var: Optional[str] = None,
                          include_interactions: bool = True,
                          include_quadratic: bool = True,
                          validate_vars: bool = True) -> Dict:
    """
    Executa an√°lise completa de elasticidade com vari√°veis parametriz√°veis
    
    Parameters:
    -----------
    anomes_treino : List[int]
        Lista de per√≠odos para treino (ex: [202501, 202502, 202503])
    anomes_teste : List[int]
        Lista de per√≠odos para teste (ex: [202504])
    categorical_vars : List[str], optional
        Lista de vari√°veis categ√≥ricas a usar. Se None, usa DEFAULT_CAT_VARS
    prod_var : str, optional
        Vari√°vel de produ√ß√£o. Se None, usa DEFAULT_PROD_VAR
    taxa_var : str, optional
        Vari√°vel de taxa. Se None, usa DEFAULT_TAXA_VAR
    include_interactions : bool
        Se True, inclui intera√ß√µes no modelo
    include_quadratic : bool
        Se True, inclui termo quadr√°tico
    validate_vars : bool
        Se True, valida as vari√°veis categ√≥ricas
    
    Returns:
    --------
    Dict: Dicion√°rio com todos os resultados da an√°lise
    """
    
    print("="*60)
    print("üöÄ MODELO DE ELASTICIDADE - FINANCIAMENTO DE VE√çCULOS")
    print("="*60)
    print(f"üìÖ Per√≠odos de Treino: {anomes_treino}")
    print(f"üìÖ Per√≠odos de Teste: {anomes_teste}")
    
    # Usar vari√°veis padr√£o se n√£o especificadas
    if prod_var is None:
        prod_var = DEFAULT_PROD_VAR
    if taxa_var is None:
        taxa_var = DEFAULT_TAXA_VAR
    if categorical_vars is None:
        categorical_vars = DEFAULT_CAT_VARS
    
    print(f"\nüìä Configura√ß√£o:")
    print(f"   - Vari√°vel de produ√ß√£o: {prod_var}")
    print(f"   - Vari√°vel de taxa: {taxa_var}")
    print(f"   - Vari√°veis categ√≥ricas solicitadas: {categorical_vars}")
    
    # 1. Carregar dados
    all_periods = anomes_treino + anomes_teste
    df = load_and_prepare_data(all_periods)
    
    # 2. Validar vari√°veis categ√≥ricas
    if validate_vars:
        cat_vars = validate_categorical_vars(df, categorical_vars)
    else:
        cat_vars = categorical_vars
        print(f"\n‚ö†Ô∏è  Valida√ß√£o de vari√°veis desabilitada")
        print(f"    Usando: {cat_vars}")
    
    # 3. An√°lise explorat√≥ria
    perform_eda(df, prod_var, taxa_var, cat_vars)
    
    # 4. An√°lise de import√¢ncia das features
    if cat_vars:
        importance_df = analyze_feature_importance(df, prod_var, taxa_var, cat_vars)
    else:
        print("\n‚ö†Ô∏è  An√°lise de import√¢ncia ignorada (sem vari√°veis categ√≥ricas)")
        importance_df = None
    
    # 5. Preparar dados para modelagem
    train_data, test_data = prepare_modeling_data(
        df, prod_var, taxa_var, cat_vars, anomes_treino, anomes_teste
    )
    
    # 6. Construir modelo
    model, train_data, test_data = build_elasticity_model(
        train_data, test_data, prod_var, taxa_var, cat_vars,
        include_interactions=include_interactions,
        include_quadratic=include_quadratic
    )
    
    # 7. Calcular elasticidades por segmento
    elasticities = calculate_segment_elasticities(
        model, train_data, taxa_var, cat_vars
    )
    
    # 8. Diagn√≥stico do modelo
    metrics = model_diagnostics(model, train_data, test_data)
    
    # 9. Simular cen√°rios
    scenarios_df = simulate_pricing_scenarios(
        model, train_data, taxa_var, cat_vars
    )
    
    print("\n" + "="*60)
    print("‚úÖ AN√ÅLISE CONCLU√çDA COM SUCESSO!")
    print("="*60)
    print(f"   Vari√°veis categ√≥ricas utilizadas: {cat_vars}")
    print("="*60)
    
    return {
        'model': model,
        'train_data': train_data,
        'test_data': test_data,
        'elasticities': elasticities,
        'metrics': metrics,
        'scenarios': scenarios_df,
        'categorical_vars_used': cat_vars,
        'importance_df': importance_df
    }

# ==========================================
# EXEMPLOS DE USO
# ==========================================

if __name__ == "__main__":
    # Definir per√≠odos de an√°lise
    ANOMES_TREINO = [202501, 202502, 202503]  # Janeiro a Mar√ßo 2025
    ANOMES_TESTE = [202504]                   # Abril 2025
    
    # ====== EXEMPLO 1: Usar configura√ß√£o padr√£o ======
    print("\nüîπ EXEMPLO 1: Configura√ß√£o Padr√£o")
    results1 = run_elasticity_analysis(
        anomes_treino=ANOMES_TREINO,
        anomes_teste=ANOMES_TESTE
    )
    
    # ====== EXEMPLO 2: Especificar vari√°veis categ√≥ricas ======
    print("\nüîπ EXEMPLO 2: Vari√°veis Categ√≥ricas Customizadas")
    results2 = run_elasticity_analysis(
        anomes_treino=ANOMES_TREINO,
        anomes_teste=ANOMES_TESTE,
        categorical_vars=['uf', 'seg_cliente'],  # Apenas UF e segmento
        include_interactions=True,
        include_quadratic=True
    )
    
    # ====== EXEMPLO 3: Modelo sem intera√ß√µes ======
    print("\nüîπ EXEMPLO 3: Modelo Sem Intera√ß√µes")
    results3 = run_elasticity_analysis(
        anomes_treino=ANOMES_TREINO,
        anomes_teste=ANOMES_TESTE,
        categorical_vars=['rating_price'],  # Apenas rating
        include_interactions=False,  # Sem intera√ß√µes
        include_quadratic=False      # Sem termo quadr√°tico
    )
    
    # ====== EXEMPLO 4: Adicionar novas vari√°veis categ√≥ricas ======
    print("\nüîπ EXEMPLO 4: Testando Novas Vari√°veis")
    results4 = run_elasticity_analysis(
        anomes_treino=ANOMES_TREINO,
        anomes_teste=ANOMES_TESTE,
        categorical_vars=['uf', 'rating_price', 'seg_cliente', 'tipo_veiculo', 'canal_venda'],
        validate_vars=True  # Validar se existem no dataset
    )
    
    # ====== EXEMPLO 5: An√°lise m√≠nima (sem segmenta√ß√£o) ======
    print("\nüîπ EXEMPLO 5: Modelo Sem Segmenta√ß√£o")
    results5 = run_elasticity_analysis(
        anomes_treino=ANOMES_TREINO,
        anomes_teste=ANOMES_TESTE,
        categorical_vars=[],  # Sem vari√°veis categ√≥ricas
        include_interactions=False,
        include_quadratic=True
    )
    
    # Os resultados podem ser acessados atrav√©s dos dicion√°rios
    # results['model'] - modelo treinado
    # results['elasticities'] - elasticidades por segmento
    # results['metrics'] - m√©tricas de performance
    # results['scenarios'] - cen√°rios simulados
    # results['categorical_vars_used'] - vari√°veis efetivamente utilizadas
    # results['importance_df'] - import√¢ncia das vari√°veis